{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a95c82db-03cc-43f2-b225-a7e85da005e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmxnet\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgluon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[32m      9\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m torch.manual_seed(\u001b[32m42\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(42)\n",
    "\n",
    "alex_transformer = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.1307, std=0.3081),])\n",
    "\n",
    "fashion_train_data = mxnet.gluon.data.vision.datasets.FashionMNIST(train=True, transform=alex_transformer)\n",
    "fashion_test_data = mxnet.gluon.data.vision.datasets.FashionMNIST(train=False, transform=alex_transformer)\n",
    "\n",
    "fashion_batch_size = 256\n",
    "train_dataloader = mx.gluon.data.DataLoader(fashion_train_data, batch_size=fashion_batch_size, shuffle=False)\n",
    "test_dataloader = mx.gluon.data.DataLoader(fashion_test_data, batch_size=fashion_batch_size, shuffle=False)\n",
    "\n",
    "def build_alexnet():\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0.01)\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2, activation='relu'),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2, activation='relu'),\n",
    "        #nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(4096, activation='relu'),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(4096, activation='relu'),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(10, activation=None),\n",
    "        # nn.Linear(4096, 4096),\n",
    "        # nn.ReLU(inplace=True),\n",
    "        # nn.Dropout(p=0.5),\n",
    "        #nn.Linear(4096, 10)\n",
    "    )\n",
    "\n",
    "    net.apply(init_weights)\n",
    "    return net\n",
    "\n",
    "alexnet = build_alexnet().to(device)\n",
    "\n",
    "def train(net, train_loader, device, num_epochs, learning_rate):\n",
    "    net.train()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    acc_history = []\n",
    "\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    with tqdm(total=total_steps, position=0, leave=True) as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                batch_total = labels.size(0)\n",
    "                batch_correct = (preds == labels).sum().item()\n",
    "                total += batch_total\n",
    "                correct += batch_correct\n",
    "                batch_acc = batch_correct / batch_total\n",
    "\n",
    "                pbar.set_description(f\"Epoch {epoch+1}/{num_epochs} | Loss {running_loss:.2f} | Acc {batch_acc:.3f}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "            acc = correct / total\n",
    "            acc_history.append(acc)\n",
    "\n",
    "    return acc_history\n",
    "\n",
    "# Запуск обучения\n",
    "hist_alexnet = train(alexnet, train_dataloader, device, num_epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cf89c4-0609-4838-a682-bc35de9c981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(42)\n",
    "\n",
    "alex_transformer = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.1307], std=[0.3081]),\n",
    "])\n",
    "\n",
    "fashion_train_data = datasets.FashionMNIST(root=\"./data\", train=True, transform=alex_transformer, download=True)\n",
    "fashion_test_data = datasets.FashionMNIST(root=\"./data\", train=False, transform=alex_transformer, download=True)\n",
    "\n",
    "fashion_batch_size = 256\n",
    "train_dataloader = torch.utils.data.DataLoader(fashion_train_data, batch_size=fashion_batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(fashion_test_data, batch_size=fashion_batch_size, shuffle=False)\n",
    "\n",
    "def build_alexnet():\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0.01)\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256 * 6 * 6, 4096),  # Правильный размер после сверток\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10),\n",
    "    )\n",
    "\n",
    "    net.apply(init_weights)\n",
    "    return net\n",
    "\n",
    "alexnet = build_alexnet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3331dd27-36b8-4e1f-9bb3-0c82b1723c97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                     | 0/2350 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                     | 0/2350 [00:02<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 297369600 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m acc_history\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Запуск обучения\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m hist_alexnet = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43malexnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(net, train_loader, device, num_epochs, learning_rate)\u001b[39m\n\u001b[32m     18\u001b[39m labels = labels.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     20\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m outputs = \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     23\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Pessonal Pricing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Pessonal Pricing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Pessonal Pricing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Pessonal Pricing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Pessonal Pricing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Pessonal Pricing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Pessonal Pricing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 297369600 bytes."
     ]
    }
   ],
   "source": [
    "def train(net, train_loader, device, num_epochs, learning_rate):\n",
    "    net.train()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    acc_history = []\n",
    "\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    with tqdm(total=total_steps, position=0, leave=True) as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                batch_total = labels.size(0)\n",
    "                batch_correct = (preds == labels).sum().item()\n",
    "                total += batch_total\n",
    "                correct += batch_correct\n",
    "                batch_acc = batch_correct / batch_total\n",
    "\n",
    "                pbar.set_postfix({'Loss': f'{running_loss:.2f}',\n",
    "                'Acc': f'{batch_acc:.3f}'})\n",
    "                \n",
    "                # pbar.set_description(f\"Epoch {epoch+1}/{num_epochs} | Loss {running_loss:.2f} | Acc {batch_acc:.3f}\")\n",
    "                # pbar.update(1)\n",
    "\n",
    "            acc = correct / total\n",
    "            acc_history.append(acc)\n",
    "\n",
    "    return acc_history\n",
    "\n",
    "# Запуск обучения\n",
    "hist_alexnet = train(alexnet, train_dataloader, device, num_epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441b358-a6d5-43a0-aaa0-a256f97c5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "import time\n",
    "\n",
    "# Устанавливаем контекст CPU\n",
    "ctx = mx.cpu()\n",
    "\n",
    "# Трансформер для FashionMNIST\n",
    "fashion_transformer = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.1307, std=0.3081)\n",
    "])\n",
    "\n",
    "# Загружаем данные\n",
    "fashion_train_data = datasets.FashionMNIST(train=True).transform_first(fashion_transformer)\n",
    "fashion_test_data = datasets.FashionMNIST(train=False).transform_first(fashion_transformer)\n",
    "\n",
    "# DataLoader с меньшим батчем\n",
    "fashion_batch_size = 128  # Уменьшили с 256 до 128\n",
    "train_dataloader = gluon.data.DataLoader(fashion_train_data, batch_size=fashion_batch_size, shuffle=True)\n",
    "test_dataloader = gluon.data.DataLoader(fashion_test_data, batch_size=fashion_batch_size, shuffle=False)\n",
    "\n",
    "# Архитектура AlexNet\n",
    "def build_alexnet():\n",
    "    net = nn.Sequential()\n",
    "    \n",
    "    # Первый блок\n",
    "    net.add(nn.Conv2D(channels=96, kernel_size=11, strides=4, padding=2, activation='relu'))\n",
    "    net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    \n",
    "    # Второй блок\n",
    "    net.add(nn.Conv2D(channels=256, kernel_size=5, padding=2, activation='relu'))\n",
    "    net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    \n",
    "    # Третий блок\n",
    "    net.add(nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu'))\n",
    "    net.add(nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu'))\n",
    "    net.add(nn.Conv2D(channels=256, kernel_size=3, padding=1, activation='relu'))\n",
    "    net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    \n",
    "    # Полносвязные слои\n",
    "    net.add(nn.Flatten())\n",
    "    net.add(nn.Dense(4096, activation='relu'))\n",
    "    net.add(nn.Dropout(0.5))\n",
    "    net.add(nn.Dense(4096, activation='relu'))\n",
    "    net.add(nn.Dropout(0.5))\n",
    "    net.add(nn.Dense(10))\n",
    "    \n",
    "    return net\n",
    "\n",
    "# Создаем модель\n",
    "alexnet = build_alexnet()\n",
    "alexnet.initialize(ctx=ctx)\n",
    "\n",
    "# Инициализация весов\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Dense):\n",
    "        m.weight.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "        if m.bias is not None:\n",
    "            m.bias.initialize(mx.init.Constant(0.01), ctx=ctx)\n",
    "    elif isinstance(m, nn.Conv2D):\n",
    "        m.weight.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "        if m.bias is not None:\n",
    "            m.bias.initialize(mx.init.Zeros(), ctx=ctx)\n",
    "\n",
    "alexnet.apply(init_weights)\n",
    "\n",
    "# Функция обучения\n",
    "def train(net, train_loader, ctx, num_epochs, learning_rate):\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': learning_rate, 'momentum': 0.9})\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, (data, label) in enumerate(train_loader):\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            \n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "            \n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            train_acc += nd.mean(output.argmax(axis=1) == label).asscalar()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(train_loader)}, Loss: {train_loss/num_batches:.4f}, Acc: {train_acc/num_batches:.4f}')\n",
    "        \n",
    "        print(f'Epoch {epoch+1} completed - Loss: {train_loss/num_batches:.4f}, Accuracy: {train_acc/num_batches:.4f}')\n",
    "\n",
    "# Запуск обучения\n",
    "print(\"Начинаем обучение...\")\n",
    "train(alexnet, train_dataloader, ctx, num_epochs=10, learning_rate=0.01)\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db0b85-2647-469b-b994-1396f9987123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
